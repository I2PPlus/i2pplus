#!/bin/sh
# Graceful I2P+ Router Updater
# Downloads i2pupdate.zip and performs graceful/hard restarts

I2P="" # Set to directory containing ./i2prouter (auto-detected if empty)

## Advanced Configuration (edit this section for defaults)
## These settings apply when NO command-line options are provided

# Verbosity levels (quiet overrides verbose/debug)
verbose="true"    # Show progress messages
debug=""          # Show debug output
quiet=""          # Suppress all output (overrides above)

# Downloaders to enable (default: all three)
use_eepget=""     # I2P-native downloader (default)
use_curl=""       # curl (requires proxy for .i2p/.onion)
use_wget=""       # wget (requires proxy for .i2p/.onion)

# Download behavior
retries="3"       # Retry attempts per URL
timeout="120"     # Connection timeout in seconds
stable=""         # Enable stable release downloads
devel=""          # Enable devel release downloads

# Network sources (default: i2p + b32)
use_i2p=""        # skank.i2p (default)
use_b32=""        # B32 address fallback
use_tor=""        # Onion service
use_clear=""      # Clearnet (GitHub/GitLab)
any=""            # Try ALL available sources

# Proxy configuration
proxy=""          # Default: 127.0.0.1:4444
                  # • eepget: Uses as raw address (no scheme needed)
                  # • curl/wget: Auto-adds http:// (or https:// with --ssl)

# Cron mode (skip download if no update available)
cron=""           # Enable header-based update checking
cron_file="./updatecheck.txt"

# Custom downloader arguments (advanced - use with caution)
eepget_args=""
curl_args=""
wget_args=""

## END Configuration ##

set -e  # Exit on unhandled errors

# Auto-detect I2P directory if not set
if [ -z "$I2P" ]; then
    I2P="$(cd "$(dirname "$0")" && pwd)"
fi

if [ ! -d "$I2P" ]; then
    printf 'ERROR: I2P directory not found at %s\n' "$I2P" >&2
    printf 'Please set I2P variable in script or run from router directory\n' >&2
    exit 1
fi

download_dir="$I2P"

send_help() {
    cat <<'HELP_EOF'
USAGE
  graceful_update.sh <release> [options]

RELEASE (required unless -u specified)
  stable    Download latest stable release and restart router
  devel     Download latest development release and restart router

COMMON OPTIONS
  -u URL    Download from custom URL (bypasses release selection)
  -n        DRY RUN: Show commands without executing
  -nr       Skip restart after successful download
  --restart Hard restart (no graceful tunnel shutdown)

DOWNLOADERS (can combine multiple)
  -e        Use eepget (I2P-native, no DNS leaks)
  -c        Use curl (requires proxy for .i2p/.onion)
  -w        Use wget (requires proxy for .i2p/.onion)
            Default: all three downloaders tried sequentially

NETWORK SOURCES (can combine multiple)
  --i2p     skank.i2p (default stable/devel source)
  --b32     B32 address fallback (default if .i2p fails)
  --tor     Onion service (requires Tor proxy)
  --clear   Clearnet sources (GitHub releases + GitLab artifacts)
  --any     Try ALL available sources until success

PROXY HANDLING
  -p PROXY  Set proxy address (default: 127.0.0.1:4444)
            • eepget: Uses as raw address (e.g., 127.0.0.1:4444)
            • curl/wget: Auto-adds http:// prefix if missing
            • Use --ssl to force https:// prefix for curl/wget
            • SOCKS5: Use socks5h:// prefix for DNS-through-proxy
  --insecure  Allow insecure SSL connections (clearnet only)

ADVANCED OPTIONS
  -r NUM    Retry attempts per URL (default: 3)
  -t SECS   Connection timeout (default: 120 seconds)
  --pid FILE  Custom PID file location
  --cron    Skip download if server's Last-Modified unchanged
            (uses ./updatecheck.txt to track last check)

HELP OPTIONS
  -h, --help  Show this help text
  -v          Verbose output (default)
  -d          Debug output (shows commands being run)
  -q          Quiet mode (suppresses all non-error output)

EXAMPLES
  # Standard stable update with graceful restart
  ./graceful_update.sh stable

  # Development update using only eepget over I2P
  ./graceful_update.sh devel -e --i2p

  # Clearnet update with custom proxy (Tor)
  ./graceful_update.sh stable --clear -p socks5h://127.0.0.1:9050

  # Dry run to preview commands
  ./graceful_update.sh stable -n

  # Cron job: only download if update available
  ./graceful_update.sh stable --cron

SECURITY NOTES
  • DNS leak protection: curl/wget BLOCK .i2p/.onion downloads without proxy
  • All downloads validated as ZIP files before installation
  • Atomic updates: download to temp file → validate → replace existing
  • PID locking prevents concurrent execution

DEFAULT BEHAVIOR
  Downloads stable release using eepget → curl → wget from:
    1. skank.i2p (primary)
    2. B32 address (fallback)
  Then performs graceful router restart (waits for tunnel expiration)

EXIT CODES
  0 = Success
  1 = Usage/configuration error
  3 = Download configuration error
  4 = Router restart failure
  5+ = Other failures

HELP_EOF

    if [ -n "$1" ]; then exit "$1"; else exit 0; fi
}

# Require at least one argument
if [ -z "$1" ]; then
    send_help 1
fi

# Parse command-line arguments safely
while [ $# -gt 0 ]; do
    case "$1" in
        -e) use_eepget="true"; downloader="${downloader:+$downloader }eepget"; shift ;;
        -c) use_curl="true"; downloader="${downloader:+$downloader }curl"; shift ;;
        -w) use_wget="true"; downloader="${downloader:+$downloader }wget"; shift ;;
        -u)
            shift
            [ -z "$1" ] && { printf 'ERROR: -u requires URL argument\n' >&2; send_help 1; }
            use_url="true"
            url=$(printf '%s\n' "$1" | grep -iEo 'https?://[^[:space:]]{1,}')
            [ -z "$url" ] && { printf 'ERROR: Invalid URL format\n' >&2; send_help 1; }
            shift
            ;;
        -n) dry="true"; shift ;;
        -nr) no_restart="true"; shift ;;
        -d) debug="true"; shift ;;
        -v) verbose="true"; shift ;;
        -q) quiet="true"; shift ;;
        -r)
            shift
            [ -z "$1" ] || ! printf '%s\n' "$1" | grep -qE '^[0-9]+$' && {
                printf 'ERROR: -r requires positive integer\n' >&2; exit 1
            }
            retries="$1"; shift
            ;;
        -t)
            shift
            [ -z "$1" ] || ! printf '%s\n' "$1" | grep -qE '^[0-9]+$' && {
                printf 'ERROR: -t requires positive integer\n' >&2; exit 1
            }
            timeout="$1"; shift
            ;;
        -p)
            shift
            [ -z "$1" ] && { printf 'ERROR: -p requires proxy address\n' >&2; exit 1; }
            proxy="$1"; shift
            ;;
        --pid)
            shift
            [ -z "$1" ] && { printf 'ERROR: --pid requires filename\n' >&2; exit 1; }
            pid="$1"; shift
            ;;
        --any)
            any="true"
            stable_files="${stable_files:+$stable_files }i2p b32 tor clear"
            devel_files="${devel_files:+$devel_files }i2p b32 tor clear git"
            shift
            ;;
        --stable|[Ss][Tt][Aa][Bb][Ll][Ee]) stable="true"; shift ;;
        --devel|[Dd][Ee][Vv][Ee][Ll]) devel="true"; shift ;;
        --help|-h) send_help ;;
        --clear)
            use_git="true"; insecure="true"; use_clear="true"
            stable_files="${stable_files:+$stable_files }clear git"
            devel_files="${devel_files:+$devel_files }clear git"
            shift
            ;;
        --tor)
            use_tor="true"
            stable_files="${stable_files:+$stable_files }tor"
            devel_files="${devel_files:+$devel_files }tor"
            shift
            ;;
        --insecure) insecure="true"; shift ;;
        --i2p)
            use_i2p="true"; use_i2p_request="true"
            stable_files="${stable_files:+$stable_files }i2p"
            devel_files="${devel_files:+$devel_files }i2p"
            shift
            ;;
        --b32)
            use_b32="true"
            stable_files="${stable_files:+$stable_files }b32"
            devel_files="${devel_files:+$devel_files }b32"
            shift
            ;;
        --restart) restart="true"; shift ;;
        --cron) cron="true"; shift ;;
        --ssl) ssl="true"; shift ;;
        *)
            printf 'ERROR: Unknown option: %s\n\n' "$1" >&2
            send_help 1
            ;;
    esac
done

verbose() { [ -n "$verbose" ] && [ -z "$quiet" ] && printf '%s\n' "$*"; }
debug() { [ -n "$debug" ] && [ -z "$quiet" ] && printf 'DEBUG: %s\n' "$*"; }

# Validate release selection
if [ -n "$stable" ] && [ -n "$devel" ] && [ -z "$use_url" ]; then
    verbose "ERROR: Specify only ONE release type (stable OR devel)"
    exit 1
elif [ -z "$stable" ] && [ -z "$devel" ] && [ -z "$use_url" ]; then
    verbose "ERROR: Missing release type (stable/devel) or custom URL (-u)"
    send_help 1
fi

# Set defaults if unset
: "${retries:=3}"
: "${timeout:=320}"

# Enable all downloaders if none specified
if [ -z "$use_eepget" ] && [ -z "$use_curl" ] && [ -z "$use_wget" ]; then
    use_eepget="true"; use_curl="true"; use_wget="true"
    downloader="eepget curl wget"
    debug "Using default downloaders: eepget, curl, wget"
fi

# Set default proxy if unset
: "${proxy:=127.0.0.1:4444}"

# PID MANAGEMENT - ATOMIC LOCKING
if [ -n "$pid" ]; then
    PIDFILE="$pid"
    LOCKDIR="${PIDFILE}.lock"
else
    PIDFILE="$I2P/graceful_update.pid"
    LOCKDIR="${PIDFILE}.lock"
fi

cleanup() {
    rm -f "$PIDFILE" 2>/dev/null
    rm -rf "$LOCKDIR" 2>/dev/null
}

trap cleanup INT TERM EXIT HUP

# Prevent concurrent execution with atomic lock
if ! mkdir "$LOCKDIR" 2>/dev/null; then
    if [ -f "$PIDFILE" ]; then
        OLD_PID=$(cat "$PIDFILE" 2>/dev/null || echo "unknown")
        printf 'ERROR: Already running (PID %s). Exiting.\n' "$OLD_PID" >&2
    else
        printf 'ERROR: Lock exists but no PID file. Remove %s to force.\n' "$LOCKDIR" >&2
    fi
    exit 1
fi

printf '%s\n' "$$" > "$PIDFILE" || {
    printf 'ERROR: Cannot write PID file %s\n' "$PIDFILE" >&2
    exit 1
}

# SAFE COMMAND EXECUTION (NO EVAL)
run_cmd() {
    if [ -n "$dry" ]; then
        printf 'DRY RUN: '
        first=1
        for arg in "$@"; do
            [ $first -eq 1 ] || printf ' '
            first=0
            # POSIX-safe argument quoting
            printf '%s' "$arg" | sed "s/'/'\\\\''/g; s/.*/'&'/"
        done
        printf '\n'
        return 0
    else
        "$@"
    fi
}

# VALIDATE DOWNLOADED FILE
validate_zip() {
    [ -s "$1" ] || return 1  # Must have content
    # Check ZIP magic number (PK header)
    head -c4 "$1" | grep -q '^PK' 2>/dev/null
}

# PRE-RESTART VALIDATION
start_restart_precheck() {
    debug "Running pre-restart validation..."
    if [ ! -f "$I2P/i2pupdate.zip" ]; then
        verbose "ERROR: i2pupdate.zip missing after download"
        return 1
    fi

    if ! validate_zip "$I2P/i2pupdate.zip"; then
        verbose "ERROR: Downloaded file is not a valid ZIP archive"
        rm -f "$I2P/i2pupdate.zip"
        return 1
    fi

    debug "Validation passed - initiating restart sequence"
    start_restart
}

# RESTART LOGIC
start_restart() {
    if [ -n "$no_restart" ]; then
        verbose "Download complete. Skipping restart (--nr specified)."
        exit 0
    fi

    if [ -n "$restart" ]; then
        verbose "Initiating HARD restart (ignoring tunnel expiration)..."
        if run_cmd "$I2P/i2prouter" restart; then
            verbose "Router restarted successfully"
            exit 0
        else
            verbose "ERROR: Hard restart failed"
            exit 4
        fi
    fi

    # Graceful shutdown sequence
    verbose "Requesting graceful shutdown (waiting for tunnel expiration)..."
    if ! run_cmd "$I2P/i2prouter" graceful; then
        verbose "First graceful request failed - retrying in 5 seconds..."
        sleep 5
        if ! run_cmd "$I2P/i2prouter" graceful; then
            verbose "ERROR: Graceful shutdown failed twice. Manual intervention required."
            exit 4
        fi
    fi

    # Wait for router to stop (max 11 minutes = 660 seconds)
    if [ -z "$dry" ]; then
        wait_timeout=660
        while run_cmd "$I2P/i2prouter" status >/dev/null 2>&1 && [ $wait_timeout -gt 0 ]; do
            sleep 3
            wait_timeout=$((wait_timeout - 3))
        done

        if [ $wait_timeout -le 0 ]; then
            verbose "WARNING: Router did not stop within 11 minutes. Forcing restart..."
            run_cmd "$I2P/i2prouter" stop >/dev/null 2>&1 || true
        fi
    fi

    verbose "Router stopped. Starting router..."
    sleep 5

    if run_cmd "$I2P/i2prouter" start; then
        verbose "Router started successfully"
        exit 0
    else
        verbose "First start attempt failed - retrying in 15 seconds..."
        sleep 15
        if run_cmd "$I2P/i2prouter" status >/dev/null 2>&1; then
            verbose "Router is running (started externally)"
            exit 0
        elif run_cmd "$I2P/i2prouter" start; then
            verbose "Router started on second attempt"
            exit 0
        else
            verbose "ERROR: Router failed to start after update"
            exit 4
        fi
    fi
}

# LOCATE DOWNLOAD TOOLS
curl_cmd=$(command -v curl || which curl 2>/dev/null)
wget_cmd=$(command -v wget || which wget 2>/dev/null)
eepget_cmd="$I2P/eepget"
eephead_cmd="$I2P/eephead"

debug "Tool paths: eepget=$eepget_cmd, curl=$curl_cmd, wget=$wget_cmd"

# Fallback search if tools not found
if [ ! -f "$eepget_cmd" ] && [ ! -f "$eephead_cmd" ] && [ ! -f "$curl_cmd" ] && [ ! -f "$wget_cmd" ]; then
    verbose "Searching for download tools..."
    for dir in /bin /sbin /usr/bin /usr/sbin /usr/local/bin /usr/local/sbin \
               "$HOME/bin" "$HOME/i2p" "$HOME/.local/bin" "$HOME/.local/sbin"; do
        [ -d "$dir" ] || continue
        [ -f "$dir/eepget" ] && eepget_cmd="$dir/eepget" && debug "Found eepget at $dir/eepget"
        [ -f "$dir/eephead" ] && eephead_cmd="$dir/eephead" && debug "Found eephead at $dir/eephead"
        [ -f "$dir/curl" ] && curl_cmd="$dir/curl" && debug "Found curl at $dir/curl"
        [ -f "$dir/wget" ] && wget_cmd="$dir/wget" && debug "Found wget at $dir/wget"
    done
fi

# Critical: must have at least one downloader
if [ ! -f "$eepget_cmd" ] && [ ! -f "$curl_cmd" ] && [ ! -f "$wget_cmd" ]; then
    verbose "ERROR: No download tools found (eepget, curl, or wget required)"
    exit 1
fi

# Set default download sources if not specified
if [ -z "$downloader" ]; then
    downloader="eepget curl wget"
fi

if [ -n "$use_url" ]; then
    stable_files=""; devel_files=""
elif [ -z "$stable_files" ] && [ -z "$devel_files" ]; then
    [ -n "$stable" ] && stable_files="i2p b32"
    [ -n "$devel" ] && devel_files="i2p b32"
fi

# PROCESS CUSTOM DOWNLOADER ARGS (if configured)
if [ -n "$eepget_args" ] || [ -n "$curl_args" ] || [ -n "$wget_args" ]; then
    exit_after_download=0

    if [ -n "$eepget_args" ] && [ -f "$eepget_cmd" ]; then
        debug "Running custom eepget command: $eepget_args"
        if run_cmd "$eepget_cmd" "$eepget_args"; then
            verbose "Custom eepget command succeeded"
            exit_after_download=1
        else
            verbose "Custom eepget command failed"
        fi
    fi

    if [ -n "$curl_args" ] && [ -f "$curl_cmd" ]; then
        debug "Running custom curl command: $curl_args"
        if run_cmd "$curl_cmd" "$curl_args"; then
            verbose "Custom curl command succeeded"
            exit_after_download=1
        else
            verbose "Custom curl command failed"
        fi
    fi

    if [ -n "$wget_args" ] && [ -f "$wget_cmd" ]; then
        debug "Running custom wget command: $wget_args"
        if run_cmd "$wget_cmd" "$wget_args"; then
            verbose "Custom wget command succeeded"
            exit_after_download=1
        else
            verbose "Custom wget command failed"
        fi
    fi

    [ $exit_after_download -eq 1 ] && start_restart_precheck
    verbose "All custom downloader commands failed"
    exit 3
fi

# URL MAPPING FUNCTION
get_url() {
    # Format: "type;url type;url ..."
    stable_url='i2p;http://skank.i2p/i2pupdate.zip b32;http://qiii4iqrj3fwv4ucaji2oykcvsob75jviycv3ghw7dhzxg2kq53q.b32.i2p/i2pupdate.zip tor;http://eekmit7xiyu3vjgovu756xj3rzbhycwzgx4gmnyqxau64yzckiluoxad.onion/i2pupdate.zip clear;https://i2pplus.github.io/i2pupdate.zip'
    devel_url='i2p;http://skank.i2p/dev/i2pupdate.zip b32;http://qiii4iqrj3fwv4ucaji2oykcvsob75jviycv3ghw7dhzxg2kq53q.b32.i2p/dev/i2pupdate.zip tor;http://eekmit7xiyu3vjgovu756xj3rzbhycwzgx4gmnyqxau64yzckiluoxad.onion/dev/i2pupdate.zip git;https://gitlab.com/i2pplus/I2P.Plus/-/jobs/artifacts/master/raw/i2pupdate.zip?job=Java8'

    target_release="$1"
    target_type="$2"

    case "$target_release" in
        stable) set -- "$stable_url" ;;
        devel) set -- "$devel_url" ;;
        *) return 1 ;;
    esac

    while [ $# -gt 0 ]; do
        type=$(printf '%s\n' "$1" | cut -d';' -f1)
        url=$(printf '%s\n' "$1" | cut -d';' -f2)
        if [ "$type" = "$target_type" ]; then
            printf '%s\n' "$url"
            return 0
        fi
        shift
    done
    return 1
}

# VALIDATE RETRIES/TIMEOUT
printf '%s\n' "$retries" | grep -qE '^[0-9]+$' || {
    verbose "ERROR: Retries must be a positive integer (-r option)"
    exit 1
}
printf '%s\n' "$timeout" | grep -qE '^[0-9]+$' || {
    verbose "ERROR: Timeout must be a positive integer (-t option)"
    exit 1
}

# PREPARE DOWNLOADER OPTIONS
if [ -n "$use_eepget" ]; then
    eepget_retries="-n $retries"
    eepget_timeout="-t $timeout"
fi
if [ -n "$use_curl" ]; then
    curl_retries="--retry $retries --retry-delay 2 --retry-max-time $((retries * timeout))"
    curl_timeout="--connect-timeout $timeout --max-time $((timeout * 2))"
fi
if [ -n "$use_wget" ]; then
    wget_retries="--retry-connrefused --waitretry=2 --tries=$retries"
    wget_timeout="--read-timeout=$((timeout + 5)) --timeout=$timeout"
fi

# PROXY CONFIGURATION
if [ -n "$proxy" ]; then
    if [ -n "$use_eepget" ]; then
        eepget_proxy="-p $proxy"
    fi

    if [ -n "$use_wget" ]; then
        wget_proxy="-e http_proxy=http://$proxy -e https_proxy=https://$proxy"
    fi

    if [ -n "$use_curl" ]; then
        case "$proxy" in
            http://*|https://*|socks5h://*|socks5://*)
                cproxy="$proxy"
                ;;
            *)
                cproxy="${ssl:+https}http://$proxy"
                ;;
        esac
        # Ensure DNS goes through proxy for SOCKS
        cproxy=$(printf '%s\n' "$cproxy" | sed 's|^socks5://|socks5h://|i')
        curl_proxy="-x $cproxy"
    fi
fi

# INSECURE OPTIONS
if [ -n "$insecure" ]; then
    [ -n "$use_curl" ] && curl_insecure="--insecure"
    [ -n "$use_wget" ] && wget_insecure="--no-check-certificate"
fi

# CRON MODE: CHECK LAST-MODIFIED HEADER
head_check() {
    last_modified=""
    [ -f "$cron_file" ] && last_modified=$(head -n1 "$cron_file" 2>/dev/null || true)

    # Get headers without following redirects (-I for curl, -S for wget)
    headers=$("$@" 2>/dev/null) || return 0

    # Extract Last-Modified header (case-insensitive)
    modified=$(printf '%s\n' "$headers" | grep -i '^last-modified:' | head -n1 | \
               sed 's/^[Ll][Aa][Ss][Tt]-[Mm][Oo][Dd][Ii][Ff][Ii][Ee][Dd]:[[:space:]]*//' || true)

    [ -z "$modified" ] && {
        debug "No Last-Modified header - assuming update needed"
        return 0
    }

    if [ "$last_modified" = "$modified" ]; then
        verbose "No update available (Last-Modified unchanged)"
        return 1  # No update needed
    else
        printf '%s\n' "$modified" > "$cron_file" 2>/dev/null || true
        debug "Update available (Last-Modified changed from '$last_modified' to '$modified')"
        return 0  # Update needed
    fi
}

# ATOMIC DOWNLOAD WITH VALIDATION
download_file() {
    downloader_name="$1"
    downloader_cmd="$2"
    shift 2

    tmpfile=$(mktemp -p "$I2P" "i2pupdate.XXXXXX.zip") || {
        verbose "ERROR: Cannot create temporary file"
        return 1
    }
    trap 'rm -f "$tmpfile"' EXIT

    if run_cmd "$downloader_cmd" "$@" -o "$tmpfile" "$url"; then
        if validate_zip "$tmpfile"; then
            mv "$tmpfile" "$I2P/i2pupdate.zip" || {
                verbose "ERROR: Cannot move downloaded file to final location"
                return 1
            }
            verbose "Download successful via $downloader_name: $url"
            return 0
        else
            verbose "Download failed validation (not a valid ZIP file)"
            return 1
        fi
    else
        return 1
    fi
}

# MAIN DOWNLOAD LOOP
for downloader_type in $downloader; do
    case "$downloader_type" in
        eepget)
            [ ! -f "$eepget_cmd" ] && { verbose "Skipping eepget (not found)"; continue; }
             # Determine URL sources to try
            [ -n "$use_url" ] && sources="custom" || {
                [ -n "$stable" ] && sources="$stable_files"
                [ -n "$devel" ] && sources="$devel_files"
            }
             for src in $sources; do
                [ "$src" = "custom" ] && url="$url" || url=$(get_url "${stable:+stable}${devel:+devel}" "$src") || continue
                 # Cron check (only once per downloader type)
                if [ -n "$cron" ] && [ -z "$cron_checked" ]; then
                    cron_checked="true"
                    eephead_cmd="$eephead_cmd $eepget_retries $eepget_timeout $eepget_proxy $url"
                    if ! head_check "$eephead_cmd"; then
                        verbose "Cron mode: No update available"
                        exit 0
                    fi
                fi
                 debug "Trying eepget ($src): $url"
                if download_file "eepget" "$eepget_cmd" "$eepget_retries" "$eepget_timeout" "$eepget_proxy"; then
                    start_restart_precheck
                fi
            done
            ;;
        curl)
            [ ! -f "$curl_cmd" ] && { verbose "Skipping curl (not found)"; continue; }
             [ -n "$use_url" ] && sources="custom" || {
                [ -n "$stable" ] && sources="$stable_files"
                [ -n "$devel" ] && sources="$devel_files"
            }
             for src in $sources; do
                [ "$src" = "custom" ] && url="$url" || url=$(get_url "${stable:+stable}${devel:+devel}" "$src") || continue
                 # DNS leak protection
                case "$url" in
                    *.onion/*|*.i2p/*)
                        if [ -z "$proxy" ]; then
                            verbose "curl skipped: $url requires proxy for .onion/.i2p (DNS leak protection)"
                            continue 2
                        fi
                        ;;
                esac
                 # GitLab artifact URL handling (preserved per request)
                [ "$src" = "git" ] && url=$("$curl_cmd" --raw -q -s "$curl_retries" "$curl_timeout" "$curl_proxy" "$url" | cut -d'"' -f2)
                 if [ -n "$cron" ] && [ -z "$cron_checked" ]; then
                    cron_checked="true"
                    curlhead_cmd="$curl_cmd -I $curl_retries $curl_timeout $curl_proxy $url"
                    if ! head_check "$curlhead_cmd"; then
                        verbose "Cron mode: No update available"
                        exit 0
                    fi
                fi
                 debug "Trying curl ($src): $url"
                if download_file "curl" "$curl_cmd" "$curl_insecure" "$curl_retries" "$curl_timeout" "$curl_proxy"; then
                    start_restart_precheck
                fi
            done
            ;;
        wget)
            [ ! -f "$wget_cmd" ] && { verbose "Skipping wget (not found)"; continue; }
             [ -n "$verbose" ] && wget_verbosity="-v" || wget_verbosity="-q"
             attempt=1
            while [ $attempt -le "$retries" ]; do
                [ -n "$use_url" ] && sources="custom" || {
                    [ -n "$stable" ] && sources="$stable_files"
                    [ -n "$devel" ] && sources="$devel_files"
                }
              for src in $sources; do
                if [ "$src" = "custom" ]; then
                    : # url already set
                else
                    url=$(get_url "${stable:+stable}${devel:+devel}" "$src") || continue
                fi
                     # DNS leak protection
                    case "$url" in
                        *.onion/*|*.i2p/*)
                            if [ -z "$proxy" ]; then
                                verbose "wget skipped: $url requires proxy for .onion/.i2p (DNS leak protection)"
                                continue 2
                            fi
                            ;;
                    esac
                     if [ -n "$cron" ] && [ $attempt -eq 1 ] && [ -z "$cron_checked" ]; then
                        cron_checked="true"
                        wgethead_cmd="$wget_cmd -S -O /dev/null -q $url"
                        if ! head_check "$wgethead_cmd"; then
                            verbose "Cron mode: No update available"
                            exit 0
                        fi
                    fi
                     debug "Trying wget ($src) attempt $attempt: $url"
                    if download_file "wget" "$wget_cmd" "$wget_proxy" "$wget_insecure" "$wget_verbosity" "$wget_retries" "$wget_timeout"; then
                        start_restart_precheck
                    fi
                done
                 attempt=$((attempt + 1))
                [ $attempt -le "$retries" ] && sleep 2
            done
            ;;
    esac
done

verbose "ERROR: All download attempts failed"
verbose "  • Check network connectivity and proxy settings"
verbose "  • Verify I2P router is running (for .i2p downloads)"
verbose "  • Try --clear for clearnet fallback sources"
exit 1